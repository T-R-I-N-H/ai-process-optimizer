from google import genai
import os
import logging

logger = logging.getLogger(__name__)

# Configure Gemini API
try:
    client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
    logger.info("Gemini Client initialized successfully.")
except Exception as e:
    logger.error(f"Failed to configure Gemini Client: {e}")
    client = None

def call_gemini(prompt: str, temperature: float = 0.7, max_output_tokens: int = 1000) -> str:
    """Helper function to call the Gemini API using the latest client interface."""
    if client is None:
        logger.error("Gemini client is not initialized. Cannot call Gemini API.")
        return "ERROR: LLM service not available."

    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=prompt,
            # generation_config={
            #     "temperature": temperature,
            #     "max_output_tokens": max_output_tokens
            # }
        )
        if hasattr(response, 'text') and response.text:
            return response.text
        else:
            logger.warning(f"Gemini API returned no text content for prompt: {prompt[:100]}...")
            return "ERROR: No content generated by LLM."
    except Exception as e:
        logger.error(f"Error calling Gemini API for prompt: {prompt[:100]}... Error: {e}")
        return "ERROR: Could not generate response from LLM."