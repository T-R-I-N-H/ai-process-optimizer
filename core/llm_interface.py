from google import genai
from google.genai import types
import os
import logging

logger = logging.getLogger(__name__)

# Configure Gemini API
try:
    client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
    logger.info("Gemini Client initialized successfully.")
except Exception as e:
    logger.error(f"Failed to configure Gemini Client: {e}")
    client = None

def call_gemini(prompt: str, temperature: float = 0.7, max_output_tokens: int = 1000) -> str:
    """Helper function to call the Gemini API using the latest client interface."""
    if client is None:
        logger.error("Gemini client is not initialized. Cannot call Gemini API.")
        return "ERROR: LLM service not available."

    try:
        response = client.models.generate_content(
            model='gemini-2.5-pro',
            contents=prompt,
            config=types.GenerateContentConfig(
                system_instruction='You are a smart AI assistance, developed by TRINH team. You can assist user with process visualization, optimization, and evaluation.',
                max_output_tokens= max_output_tokens,
            #     # top_k= 2,
            #     # top_p= 0.5,
                temperature= temperature,
            #     response_mime_type= 'application/json',
            #     stop_sequences= ['\n'],
            #     seed=42,
            )
        )
        if hasattr(response, 'text') and response.text:
            return response.text
        else:
            logger.warning(f"Gemini API returned no text content for prompt: {prompt[:100]}...")
            return "ERROR: No content generated by LLM."
    except Exception as e:
        logger.error(f"Error calling Gemini API for prompt: {prompt[:100]}... Error: {e}")
        return "ERROR: Could not generate response from LLM."